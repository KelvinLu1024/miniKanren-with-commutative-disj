\documentclass[format=acmlarge, review=true, authordraft=true]{acmart}

\usepackage{color}
\usepackage{textcomp}
\usepackage{hyperref}

\usepackage{trackchanges}

\addeditor{MVC}
\addeditor{LKC}
\addeditor{DPF}

\usepackage{listings}
\lstset{
  language=Scheme,
  basicstyle=\ttfamily,
  morekeywords={run,conde,run*,defrel,==,fresh,disj,conj,disj+},
  alsodigit={!\$\%&*+-./:<=>?@^_~},
  morecomment=[l]{;,\#{}lang},
  mathescape=true,
  literate={-inf}{{$^\infty$}}{1} {/fair}{{$_{fair}$}}{3}
  		   {→}{{$\rightarrow$}}{1}
  		   {×}{{$\times$}}{1}
  		   {==}{{$\equiv$}}{1}
  		   {conde}{{\textcolor[rgb]{0,.3,.7}{\textbf{cond$^e$}}}}{4}
                   {appendo}{{append$^o$}}{6}
  		   {repeato}{{repeat$^o$}}{6}
  		   {disj2}{{disj$_2$}}{4}
  		   {conj2}{{conj$_2$}}{4}
  		   {g0}{{g$_0$}}{2}
  		   {g1}{{g$_1$}}{2}
  		   {g2}{{g$_2$}}{2}
  		   {gl}{{g$_l$}}{2}
  		   {gr}{{g$_r$}}{2}
  		   {DFSi }{{DFS$_\textrm{i}$}}{3}
  		   {DFSbi}{{DFS$_\textrm{bi}$}}{3}
  		   {DFSf }{{DFS$_\textrm{f}$}}{3}
}
%% scheme-list .

% metadata

\title{Towards a miniKanren with fair search strategies}
\author{Kuang-Chen Lu}
\affiliation{Indiana University}
\author{Weixi Ma}
\affiliation{Indiana University}
\author{Daniel P. Friedman}
\affiliation{Indiana University}

\newcommand{\conde}{\texttt{cond$^e$}}
\newcommand{\conj}{\texttt{conj}}
\newcommand{\disj}{\texttt{disj}}
\newcommand{\clisting}[1]{
\begin{center}
  \begin{tabular}{c}
	\lstinputlisting{#1}
    \end{tabular}
\end{center}
}

\newcommand{\disjtwo}{\texttt{disj$_2$}}
\newcommand{\conjtwo}{\texttt{conj$_2$}}
\newcommand{\veryrecursiveo}{\texttt{very-recursive$^o$}}
\newcommand{\appendo}{\texttt{append$^o$}}
\newcommand{\reverso}{\texttt{revers$^o$}}
\newcommand{\repeato}{\texttt{repeat$^o$}}

\newcommand{\DFSi }[0]{DFS$_\textrm{i}$}
\newcommand{\DFSf }[0]{DFS$_\textrm{f}$}
\newcommand{\DFSbi}[0]{DFS$_\textrm{bi}$}
\newcommand{\BFS}[0]{BFS}
\newcommand{\BFSser}[0]{BFS$_\textrm{}$}
\newcommand{\BFSimp}[0]{BFS$_\textrm{imp}$}


\newtheorem{defn}{Definition}[section]

\begin{document}

\NOTE[LKC]{submission deadline: Mon 27 May 2019}

\begin{abstract}

We describe fairness levels in disjunction and conjunction
implementations.  Specifically, a disjunction implementation can be
fair, almost-fair, or unfair. And a conjunction implementation can
be fair or unfair.  We compare the fairness level of four search
strategies: the standard miniKanren interleaving depth-first search,
the balanced interleaving depth-first search, the fair depth-first
search, and the standard breadth-first search.
The two non-standard depth-first searches are new. And we present a new, more 
efficient and simpler implementation of the standard breadth-first search. Using 
quantitative evaluation, we argue that the two new depth-first searches are 
competitive alternatives to the standard one, 
and that our breadth-first search implementation is more efficient than 
the current one.

% We describe fairness levels in disjunction and conjunction
% implementations.  Specifically, a disjunction implementation can be
% fair, almost-fair, or unfair. And a conjunction implementation can
% be fair or unfair.  We compare the fairness level of four search
% strategies: the standard miniKanren interleaving depth-first search (\DFSi),
% the balanced interleaving depth-first search (\DFSbi), the fair depth-first
% search (\DFSf), and the standard breadth-first search (\BFSser).
% \DFSbi{} and \DFSf{} are new. And we present a new, more efficient
% and simpler implementation of \BFSser. Using quantitative evaluation, 
% we argue that
% \DFSbi{} and \DFSf{} are competitive alternatives to \DFSi, 
% and that our \BFSser{} implementation is more efficient than the current one.

% The syntax of a programming language should reflect its semantics. When 
%writing 
% a \conde{} expression in miniKanren, a programmer would expect all clauses 
% share the same chance of being explored, as these clauses are written in 
% parallel. The existing search strategy, interleaving depth-first search 
% (\DFSi{}), 
% however, prioritizes its clauses by the order how they are written down. 
% Similarly, when a \conde{} is followed by another goal conjunctively, a 
% programmer would expect states in parallel share the same chance of being 
% explored. Again, the answers by \DFSi{} is different from the 
% expectation. We have devised three new search strategies that have different 
% level of fairness in \disj{} and \conj{}.
% 

\end{abstract}

\maketitle

\section{introduction}

miniKanren is a family of relational programming languages.
\citep{Friedman:2005:RS:1121583} \citet{friedman_reasoned_2018} introduce 
miniKanren and its implementation in \emph{The Reasoned Schemer} 
and \emph{The Reasoned Schemer, 2nd Ed} (TRS2). \citet{byrd2017unified} have 
demonstrated that miniKanren programs are useful in solving several difficult
problems. miniKanren.org contains the seeds of many difficult problems and 
their solutions.

\NOTE[DPF]{[2,3] is the way to cite this, but I leave cleaning up this
paragraph to you.  Mostly the point is to also include a reference to
the two dimitris and to the first OCamren (OCanren), whatever. It is up to you
in this paragraph.  You can refer to
the two books like this ``Friedman et al[2,3] ... .'' This way the 
paragraph will have only one ``Friedman''}

\NOTE[DPF]{I have decided to agree with you that we should not use 
BFSser, so I am going to remove all occurrences.  
Also, we should say, ``Our implementation of BFS''
and then say, shortened to ``Our BFS'' and then you can use it in the table,
so one column should be Our BFS and the other should be BFS.}
\NOTE[DPF]{Occurrences of BFS (without Our) mean Seres et al. (We need only say
that once, or very occasionally}

\NOTE[DPF]{I think that subscripts i, bi, and f should
match what is in the comments above code, so it should be italic, emph,
or math, whichever was used before.}

\NOTE[DPF]{Is the spelling of reverso truly written without the last e?
Shouldn't it be reverseo with the appropriate raising of o.}

A subtlety arises 
when a \conde{} contains many clauses: not every clause has an 
equal chance of contributing to the result. As an example, consider the following 
relation \repeato{} and its invocation. 

\clisting{Figures/repeato.rkt}

Next, consider the following disjunction of invoking \repeato{} with four 
different letters.

\clisting{Figures/example.rkt}

\conde{} intuitively relates its clauses with logical \texttt{or}. And thus an 
unsuspicious beginner would expect each letter to contribute equally to the 
result, as follows.

\clisting{Figures/run-repeato-fair.rkt}

The \conde{} in TRS2, however, generates a less expected result.

\clisting{Figures/run-repeato-idfs.rkt}

The miniKanren in TRS2 implements interleaving DFS (\DFSi), the cause of this 
unexpected result. With this search strategy, each \conde{} clause takes half 
of its received computational resources and passes the other half to its 
following clauses, except for the last clause that takes all resources it 
receives. In the example above, the \texttt{a} clause takes half of all 
resourses. And the \texttt{b} clause takes a quarter. Thus \texttt{c} and 
\texttt{d} barely contribute to the result.

%In the example above, the letters \texttt{c} and \texttt{d} are 
%allocated with less resources than \texttt{a}, and thus \texttt{c} and 
%\texttt{d} barely contribute to the result.

\DFSi{} is sometimes powerful for an expert. By carefully organizing the order 
of \conde{} clauses, a miniKanren program can explore more ``interesting'' 
clauses than those uninteresting ones, and thus use computational resources 
efficiently.

% A little miniKanrener, however, may beg to differ--understanding
% implementation details and fiddling with clause order is not the first
% priority of a beginner.

\DFSi{} is not always the best choice. For instance, it might be less 
desirable for little miniKanreners -- understanding implementation details and 
fiddling with clause order is not their first priority. 
There is another reason that miniKanren could use more search strategies than
just \DFSi. In many applications, there does not exist one order that serves all
purposes. For example, a relational dependent type checker contains
clauses for constructors that build data and clauses for eliminators that use
data. When the type checker is generating simple and shallow programs,
the clauses for constructors had better be at the top of the
\conde{} expression.
When performing proof searches for complicated programs, the clauses for 
eliminators had better be at the top of the \conde{} expression. With \DFSi, 
these two uses cannot be efficient at the same time. In fact, to make one use 
efficient, the other one must be more sluggish.

The specification that gives every clause in the same \conde{} equal 
``search priority'' is fair \disj{}. And search strategies with 
almost-fair \disj{} give every clause similar priority. 
Fair \conj{}, a related concept, is more subtle. We cover it in the next 
section.

To summarize our contributions, we
\begin{itemize}
	\item propose and implement \textbf{b}alanced \textbf{i}nterleaving 
depth-first search (\DFSbi{}), a new search strategy with almost-fair \disj{}.
	\item propose and implement \textbf{f}air depth-first search (\DFSf{}), 
a new search strategy with fair \disj{}.
	\item implement in a new way the standard breath-first search (\BFS), a 
search strategy with fair \disj{} and fair \conj{}. We name the current 
implementation by \citeauthor{seres1999algebra} and refer to ``our 
BFS implementation as the improved one. We formally prove
that the two BFS implementations are semantically 
equivalent, however, our BFS implementation runs faster in all 
benchmarks and is shorter.
\end{itemize}

\section{search strategies and fairness}

In this section, we define fair \disj{}, almost-fair \disj{} and fair \conj{}. 
Before going further into fairness, we give a short review of the terms:
\emph{state}, search \emph{space}, and \emph{goal}.
A \emph{state} is a collection of constraints. (Here, we restrict 
constraints to unification constraints.) Every answer corresponds to a 
state. A space is a collection of states. And a \emph{goal} is a 
function from a state to a space.

% Goals check their input states and outpust possibly extended states. A goal 
% might fail for some inputs, in which case the output search space would be 
% empty.

\NOTE[LKC]{The following paragraph is extended to include an explanation on 
\texttt{run*}}

Now we elaborate fairness by running more queries about \repeato{}. We never use 
\texttt{run*} in this paper because fairness is more interesting when we have 
an unbounded number of answers. However, it is perfectly fine to use 
\texttt{run*} with any search strategies.

\subsection{fair \texttt{disj}}

Given the following program, it is natural to expect lists of each letter to
constitute $1/4$ in the query result. \DFSi, the current search
strategy, however, results in many more lists of \texttt{a}s than lists
of other letters. And some letters  (e.g. \texttt{c} and \texttt{d}) are
rarely seen. The situation would be exacerbated if the \conde{} would have
contained more clauses.

\begin{center}
	\begin{tabular}{c}
		\lstinputlisting{Figures/repeato-disj-DFSi.rkt}
	\end{tabular}
\end{center}

Under the hood, the \conde{} here is allocating computational resources to 
four trivially different search spaces. The unfair \disj{} in 
\DFSi{} allocates many more resources to the first search space. On the 
contrary, fair \disj{} would allocate resources evenly to each search space. 

\begin{center}
	\begin{tabular}{l|r}
		\lstinputlisting{Figures/repeato-disj-DFSf.rkt} &
		\lstinputlisting{Figures/repeato-disj-BFS.rkt}
	\end{tabular}
\end{center}

Running the same program again with almost-fair \disj {} (e.g. 
\DFSbi{}) gives the same result. Almost-fair, however, is not 
completely fair, as shown by the following example. 

\begin{center}
	\begin{tabular}{c}
		\lstinputlisting{Figures/repeato-disj-DFSbi.rkt}
	\end{tabular}
\end{center}

\DFSbi{} is fair only when the number of goals is a power of 2, 
otherwise, it allocates some goals twice as many resources as the 
others. In the above example, where the \conde{} has five clauses, \DFSbi{} 
allocates more resources to the clauses of \texttt{b}, \texttt{c}, and 
\texttt{d}.

We end this subsection with precise definitions of all levels of 
\disj{} fairness. Our definition of \emph{fair} \disj{} is slightly 
more general
than the one in \citet{seres1999algebra}. Their definition is only
for binary disjunction. We generalize it to a multi-arity one.

\begin{defn}[fair \disj{}]
A \disj{} is fair if and only if it allocates computational resources evenly to 
search spaces produced by goals in the same disjunction 
(i.e., clauses in the same \conde).
\end{defn}

\begin{defn}[almost-fair \disj{}]
A \disj{} is almost-fair if and only if it allocates computational resources
so evenly to search spaces produced by goals in the same disjunction that 
the maximal ratio of resources is bounded by a constant.
\end{defn}

\begin{defn}[unfair \disj{}]
A \disj{} is unfair if and only if it is not almost-fair.
\end{defn}

\subsection{fair \texttt{conj}}
\label{sec:fairconj}

Given the following program, it is natural to expect lists of each letter to
constitute $1/4$ in the answer list. Search strategies with unfair \conj{} 
(e.g. 
\DFSi, \DFSbi, \DFSf), however, results in many more lists of \texttt{a}s than 
lists of other letters. And some letters are rarely seen. The situation would 
be exacerbated if \conde{} were to contain more clauses.
Although some strategies have a different level of fairness in \disj{}, they 
have the same behavior when there is no call to a relational definition in 
\conde{} clauses (including this case).

\begin{center}
\begin{tabular}{l|c|r}
    \lstinputlisting{Figures/repeato-conj-DFSi.rkt} &
    \lstinputlisting{Figures/repeato-conj-DFSf.rkt} &
    \lstinputlisting{Figures/repeato-conj-DFSbi.rkt} \\
\end{tabular}
\end{center}

Under the hood, the \conde{} and the call to \repeato{} are connected by 
\conj{}. The \conde{} goal outputs a search space including four trivially 
different states. 
Applying the next conjunctive goal, \texttt{(repeato x q)}, produces four 
trivially different search spaces.
In the examples above, all search strategies allocate more computational 
resources to the search space of \texttt{a}. On the contrary, fair \conj{} 
would allocate resources evenly to each search space. For example,

\begin{center}
	\begin{tabular}{c}
		\lstinputlisting{Figures/repeato-conj-BFS.rkt}
	\end{tabular}
\end{center}

A more interesting situation is when the first conjunct produces an unbounded
number of states. Consider the following example, a naive specification of 
fair \conj{} 
might require search strategies to produce all sorts of singleton lists, but 
there
would not be any lists of length two or longer, which makes the strategies 
incomplete. 
A search strategy is \emph{complete} if and only if ``every correct answer 
would be discovered after some finite time'' \cite{seres1999algebra}, 
otherwise, it is \emph{incomplete}. In the 
context of miniKanren, a search strategy is complete means that every correct 
answer has a position in large enough answer lists.

\NOTE[DPF]{Was this supposed to be a note?
``We never use \texttt{run*} in this paper because fairness is only 
 interesting when we have an unbounded number of answers. However, it is 
 perfectly fine to use run* with any search strategies.''}

\begin{center}
	\begin{tabular}{c}
		\lstinputlisting{Figures/repeato-conj-infinite-naive.rkt}
	\end{tabular}
\end{center}

Our solution requires a search strategy with \emph{fair} \conj{} to organize
states in bags in search spaces, where each bag contains finite states, and 
to allocate resources evenly among search spaces derived from states in the 
same bag. It is up to a search strategy designer to decide by what criteria to 
put states in the same bag, and how to allocate resources among search spaces 
related to different bags.

\BFS{} puts states of the same cost in the same bag, and allocates
resources carefully among search spaces related to different bags such
that it produces answers in increasing order of cost. The \emph{cost}
of an answer is its depth in the search tree (i.e., the number of
calls to relations required to find them) \citep{seres1999algebra}. In
the following example, every answer is a list of a list of symbols,
where inner lists in the same outer list are identical. Here the cost of each 
answer is equal
to the length of its inner list plus the length of its outer list. For example,
the cost of \texttt{((a) (a))} is $1 + 2 = 3$.

\NOTE[DPF]{Would the answer be the same if the list had been this ((a) (b))
or did you mean structurally the same?}
\NOTE[LKC]{I have rewritten the relevant sentences.}

\begin{center}
	\begin{tabular}{c}
		\lstinputlisting{Figures/repeato-conj-infinite-sof.rkt}
	\end{tabular}
\end{center}

We end this subsection with precise definitions of all levels of \conj{} 
fairness.

\begin{defn}[fair \conj{}]
A \conj{} is fair if and only if it allocates computational resources evenly to 
search spaces produced from states in the same bag. A bag is a finite 
collection of states. And search strategies with fair \conj{} should represent 
search spaces with possibly unbounded collections of bags. 
\end{defn}

\begin{defn}[unfair \conj{}]
A \conj{} is unfair if and only if it is not fair.
\end{defn}





\section{interleaving depth-first search}

\begin{figure}
	\lstinputlisting{Figures/DFSi-0.rkt}
	\caption{implementation of \DFSi{} (Part I)}
	\label{DFSi-0}
\end{figure}

\begin{figure}
	\lstinputlisting{Figures/DFSi-1.rkt}
	\caption{implementation of \DFSi{} (Part II)}
	\label{DFSi-1}
\end{figure}

In this section, we review the implementation of interleaving depth-first 
search (\DFSi). We focus on parts that are relevant to this paper. TRS2,
chapter 10 and the appendix, ``Connecting the wires'', 
provides a comprehensive description of the 
miniKanren 
implementation but limited to unification constraints ($\equiv$).
Fig.~\ref{DFSi-0} and Fig.~\ref{DFSi-1} show parts that are later compared 
with other search 
strategies. We follow some conventions to name variables: \texttt{s}s name 
states; \texttt{g}s (possibly with subscript) name goals; 
variables ending with $^\infty$ name search spaces. Fig.~\ref{DFSi-0} shows the 
implementation of \disj. The 
first function, \disjtwo, implements binary disjunction. It applies the 
two disjunctive goals to the input state \texttt{s} and composes the two 
resulting search spaces with \texttt{append$^\infty$}. The following syntax 
definitions say \disj{} is right-associative. Fig.~\ref{DFSi-1} 
shows the implementation of \conj. The first function, \conjtwo{}, 
implements binary conjunction. 
It applies the \emph{first} goal to the input state, then applies the second 
goal to states in the resulting search space. The helper function 
\texttt{append-map$^\infty$} applies its input goal to states 
in its input search spaces and composes the resulting search spaces. It reuses 
\texttt{append$^\infty$} for search space composition. The following syntax 
definitions say \conj{} is also right-associative.
% \begin{figure}
% 	\lstinputlisting{Figures/conde.rkt}
% 	\caption{implementation of \conde}
% 	\label{conde}
% \end{figure}
% 
% The definition of \conde{} (Fig.~\ref{conde}) is shared by all search 
% strategies. It relates clauses disjunctively, and goals in the same 
% clause conjunctively.

\NOTE[DPF]{sure, go ahead and do it.}
\NOTE[LKC]{I think we can simply remove \conde{} code and its accompany 
description.}

\section{balanced interleaving depth-first search}

\begin{figure}
	\lstinputlisting{Figures/DFSbi.rkt}
	\caption{implementation of \DFSbi{}}
	\label{balanced-disj}
\end{figure}

Balanced interleaving DFS (\DFSbi{}) has an almost-fair \disj{} and unfair 
\conj{}. The implementation of \DFSbi{} differs from 
\DFSi{}'s in the \disj{} macro. We list the new \disj{} with its 
helper in Fig.~\ref{balanced-disj}. When there are one or more disjunctive 
goals, \disj{} builds a balanced binary tree whose leaves are the goals and 
whose nodes are \disjtwo{}s, hence the name of this search strategy. 
The new helper, \texttt{disj+}, takes two additional `arguments'. They 
accumulate goals to be put in the left and right subtrees. The first clause 
handles the case where there is only one goal. In this case, the tree is the 
goal itself. When there are more goals, we partition the list of goals 
into two sublists of roughly equal lengths and recur on the two sublists. We 
move goals to the accumulators in the last clause. As we are moving 
two goals each time, there are two base cases: (1) no goal remains; (2) one 
goal remains. We handle these two new base cases in the second clause and the 
third clause, respectively. In contrast, the \disj{} in \DFSi{} constructs the 
binary tree in a particularly unbalanced form.

\section{fair depth-first search}

\begin{figure}
	\lstinputlisting{Figures/DFSf.rkt}
	\caption{implementation of \DFSf{}}
	\label{fDFS}
\end{figure}

Fair DFS (\DFSf) has fair \disj{} and unfair \conj{}. The 
implementation of \DFSf{} differs from \DFSi{}'s in 
\disjtwo{} (Fig.~\ref{fDFS}). The new \disjtwo{} calls a new and 
fair version of \texttt{append$^\infty$}. \texttt{append$^\infty_{fair}$} 
immediately 
calls 
its helper, \texttt{loop}, with the first argument, \texttt{s?}, set to 
\texttt{\#{}t}, which indicates that we haven't swapped
\texttt{s$^\infty$} and \texttt{t$^\infty$}. The swapping 
happens at 
the third \texttt{cond} clause in the helper, where \texttt{s?} is updated 
accordingly. The first two \texttt{cond} clauses essentially copy the 
\texttt{car}s and stop recursion when one of the input spaces is obviously 
finite. The third clause, as we mentioned above, is just for swapping. When the 
fourth and last clause runs, we know that both \texttt{s$^\infty$} and 
\texttt{t$^\infty$} are ended with a thunk, and that we have swapped them. In 
this case, we construct a new thunk. The new thunk swaps two spaces back in the
recursive call to \texttt{loop}. This is unnecessary for fairness. We do it to 
produce answers in a more natural order.

\NOTE[DPF]{When or where do you swap them back? This could be still clearer.}
\NOTE[LKC]{Improved.}

\section{breadth-first search}

\BFS{} has both fair \disj{} and fair \conj{}. An easy implementation is based 
on \DFSf{} (not \DFSi{}): (1) replace \texttt{append$^\infty$} with 
\texttt{append$^\infty_{fair}$} in \texttt{append-map$^\infty$}'s body (2) 
rename \texttt{append-map$^\infty$} to \texttt{append-map$^\infty_{fair}$}.

% Our implementation is based 
% on \DFSf{} (not \DFSi{}). To implement \BFS{} based on \DFSf{}, 
% we need \texttt{append-map$^\infty_{fair}$} in addition to 
% \texttt{append$^\infty_{fair}$}. 
% The only difference between \texttt{append-map$^\infty$} and 
% \texttt{append-map$^\infty_{fair}$} is that the latter calls 
% \texttt{append$^\infty_{fair}$} instead of \texttt{append$^\infty$}.

\NOTE[DPF]{I need clarification: Applying the above changes won't result in ``our \BFS,'' but yet a third implementation of \BFS?}

% This implementation is improvable in two ways. First, as mentioned in 
% \autoref{sec:fairconj}, \BFS{} puts answers in bags and answers of the same 
% cost are in the same bag. In this implementation, however, it is unclear where 
% this information is recorded. Second, \texttt{append$^\infty_{fair}$} is 
% extravagant in memory usage. It makes $O(n+m)$ new \texttt{cons} cells every 
% time, where $n$ and $m$ are the ``length''s of input search spaces.

This implementation is improvable in two ways. 
First, as mentioned in \autoref{sec:fairconj}, \BFS{} puts answers in bags and 
answers of the same cost are in the same bag. In our implementation, however, 
we manage cost information subtly---the \texttt{car}s of a search space have 
cost 0 (i.e., they are all in the same bag), and every thunk indicates an 
increment in cost. It is even more subtle that \texttt{append$^\infty_{fair}$} 
and the \texttt{append-map$^\infty_{fair}$} respects the cost information. 
Second, \texttt{append$^\infty_{fair}$} is extravagant in memory usage. It 
makes $O(n+m)$ new \texttt{cons} cells every time, where $n$ and $m$ are the 
``length''s of input spaces.

\NOTE[LKC]{Should I point out that \DFSf{} also has the miserable space 
extravagance?}
\NOTE[DPF]{probably}

In the following subsections, we first describe our improved \BFS{}
implementation that manages cost information in a more clear and concise
way and is less extravagant in memory usage. 
Then we compare our BFS{} with \BFS{}, the 
current implementation by \citeauthor{seres1999algebra}.

\NOTE[DPF]{Let's use one more line and far less horizontal space
by use 3 linefeeds.  They will still align nicely.}

\subsection{improved BFS}

\begin{figure}
	\lstinputlisting{Figures/BFSimp.rkt}	
	\caption{New and changed functions in optimized BFS that implements pure 
	features}
	\label{BFSimp}
\end{figure}

% As mentioned in \autoref{sec:fairconj}, \BFS{} puts answers in bags and 
% answers of the same cost are in the same bag. 
% In the easy implementation, cost information is recorded subtly---the 
% \texttt{car}s of a search space have cost 0 (i.e. they are all in the same 
% bag),
% and every thunk indicates an increment in cost. It is even more subtle that
% \texttt{append$^\infty_{fair}$} and the \texttt{append-map$^\infty_{fair}$} 
% respects the cost information. We make these facts more obvious by changing 
% the type of search space, modifying related function definitions, and 
% introducing a few more functions.

We make the cost information more clear by changing the type of search space, 
modifying related function definitions, and introducing a few more functions.

The new type is a pair whose \texttt{car} is a list of answers (the bag), and 
whose \texttt{cdr} is either \texttt{\#{}f} or a thunk returning a search 
space. A falsy \texttt{cdr} means the search space is obviously finite. 

We list functions related to the pure subset in Fig.~\ref{BFSimp}. The first 
three functions are search space constructors. \texttt{none} makes an empty 
search space; \texttt{unit} makes a space from one answer; and \texttt{step} 
makes a space from a thunk. The remaining functions are as before. We compare 
these functions with \BFSser{} in our proof. 

Luckily, the change in \texttt{append$^\infty_{fair}$} also fixes the miserable 
space extravagance---the use of \texttt{append} helps us to reuse the first bag 
of \texttt{t$^\infty$}.

\NOTE[LKC]{I do notice that in the below paragraph the leading sentence is not 
at the beginning (but at the second position). Putting the current first 
sentence at the beginning, however, looks more fun to me.}

\citet{kiselyov2005backtracking} have demonstrated that a \emph{MonadPlus} 
hides in implementations of logic programming system. \BFSimp{} is not an 
exception: \texttt{append-map$^\infty_{fair}$} is like \texttt{bind}, but takes 
arguments in reversed order; \texttt{none}, \texttt{unit}, and 
\texttt{append$^\infty_{fair}$} correspond to \texttt{mzero}, \texttt{unit}, and 
\texttt{mplus}, respectively.

\NOTE[DPF]{I am not in love with the two calls to null?. I can think of at least
two ways to fix it.  Pick one.}

\begin{figure}
	\lstinputlisting{Figures/BFSimp-cont.rkt}	
	\caption{New and changed functions in improved BFS that implement impure 
		features}
	\label{BFSimp-cont}
\end{figure}

\NOTE[DPF]{The use of the references to Fig 7 twice tells me that something
has to change for the sake of clarity.}

Functions implementing impure features are in Fig.~\ref{BFSimp-cont}. The 
first function, \texttt{elim}, takes a space \texttt{s$^\infty$} and two 
continuations \texttt{kf} and \texttt{ks}. When \texttt{s$^\infty$} contains 
no answers, it calls \texttt{kf} with no argument. Otherwise, it calls 
\texttt{ks} with the first answer and the rest of the space. Here  `f' means 
`fail' and `s' means `succeed'. This function is similar to an eliminator of 
search spaces, hence the name. The remaining functions are as before.

\NOTE[LKC]{I swap \texttt{ks} and \texttt{kf} to mimic \texttt{ind-List}}

\NOTE[DPF]{If we forget to use {} after \reverso, the o ends up too near
the next word.  I fixed reverso on the second line of section 7, but there 
may be others.}

\subsection{compare \BFSimp{} with \BFSser{}}

In this subsection, we compare the pure subset of our BFS with \BFS{}. We 
focus on the pure subset because \BFS{} is designed for a pure 
relational programming system. We prove in Coq that these two search strategies 
are are semantically equivalent, since \texttt{(run n ? g)} produces the same 
result in both our improved \BFS{} and BFS. (See supplements for the formal proof.) To compare efficiency, we 
translate \BFS{}'s Haskell code into Racket (See supplements for the 
translated code). The translation is direct due to the similarity of the two 
relational programming systems. The translated code is longer than our \BFS{}. 
And it runs slower in all benchmarks. Details about differences in efficiency 
are in \autoref{compare-efficiency}.

\section{quantitative evaluation}

\begin{table}
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline 
		benchmark & size & \DFSi{} & \DFSbi{} & \DFSf{} & 
		\BFSimp{} & \BFSser{}  
		\\
		\hline
		\veryrecursiveo & 100000 &  579 &  793 & 2131 & 1438 & 3617 \\
		& 200000 & 1283 & 1610 & 3602 & 2803 & 4212 \\
		& 300000 & 2160 & 2836 &    - & 6137 &    - \\
		\hline 
		\appendo  & 100 &  31 &  41 &  42 &  31 &  68 \\ 
		& 200 & 224 & 222 & 221 & 226 & 218 \\ 
		& 300 & 617 & 634 & 593 & 631 & 622 \\ 
		\hline 
		\reverso & 10 &   5 &   3 &   3 &     38 &     85 \\ 
		& 20 & 107 &  98 &  51 &   4862 &   5844 \\
		& 30 & 446 & 442 & 485 & 123288 & 132159 \\ 
		\hline
		quine-1 & 1 &  71 &  44 & 69 & - & - \\ 
		& 2 & 127 & 142 & 95 & - & - \\ 
		& 3 & 114 & 114 & 93 & - & - \\ 
		\hline
		quine-2 & 1 & 147 & 112 &  56 & - & - \\ 
		& 2 & 161 & 123 & 101 & - & - \\ 
		& 3 & 289 & 189 & 104 & - & - \\ 
		\hline 
		'(I love you)-1 &  99 & 56 & 15 & 22 &  74 & 165 \\ 
		& 198 & 53 & 72 & 55 &  47 &  74 \\
		& 297 & 72 & 90 & 44 & 181 & 365 \\ 
		\hline
		'(I love you)-2 &  99 & 242 &  61 & 16 &  66 &  99 \\ 
		& 198 & 445 & 110 & 60 &  42 &  64 \\
		& 297 & 476 & 146 & 49 & 186 & 322 \\ 
		\hline 
	\end{tabular}
	\caption{The results of a quantitative evaluation: running times of 
	benchmarks 
		in milliseconds}
	\label{compare-efficiency}
\end{table}

In this section, we compare the efficiency of search strategies. A concise 
description is in Table~\ref{compare-efficiency}. A hyphen means ``running out
of memory.'' The first two benchmarks are from 
TRS2. \reverso{} is from 
\citet{rozplokhas2018improving}. The next two benchmarks 
about quine are modified from a similar test case in \citet{byrd2017unified}. 
The modifications are made 
to circumvent the need for symbolic constraints (e.g. $\neq$, 
\texttt{absent$^o$}). Our version generates de 
Bruijnized expressions and prevents closures from being inside a list. The two 
benchmarks differ in the \conde{} clause order of their relational 
interpreters. 
The last two 
benchmarks are about synthesizing expressions that evaluate to \texttt{'(I love 
you)}. This benchmark is from \citet{byrd2017unified}. Again, the 
sibling benchmarks differ in the \conde{} clause order of their relational 
interpreters. The first one 
has elimination rules (i.e. application, \texttt{car}, and \texttt{cdr}) at the 
end, while the other has them at the beginning. We conjecture that \DFSi{} 
would 
perform badly in the second case because elimination rules complicate the 
problem when synthesizing (i.e., our evaluation supports our conjecture.)

\NOTE[DPF]{There is still some clumsiness using our improved DFS, since
at some point, we may want to make this clearer, so have DFS not be fonted
is a little weird.  I think both should always use ourDFS and 
macro expand it to <our improved DFS>.  Then changes will be much easier.}

In general, only \DFSi{} and \DFSbi{} constantly perform well. \DFSf{}
is just as efficient in all benchmarks except those of \veryrecursiveo. Both
implementations of BFS have obvious overhead in many cases. Among the
three variants of DFS, which all have unfair \conj{}, \DFSf{} is most
resistant to clause permutation, followed by \DFSbi{} then
\DFSi{}. Among the two implementation of BFS, our improved \BFS{}
constantly performs as well or better. Interestingly, every strategy
with fair \disj{} suffers in \veryrecursiveo{} and \DFSf{} performs
well elsewhere. Therefore, this benchmark might be a special
case. Fair \conj{} imposes considerable overhead constantly except in
\appendo. The reason might be that strategies with fair \conj{} tend
to keep more intermediate answers in the memory.

\section{related works}

\citet{yang2010adventures} points out that a disjunct complex would be `fair' 
if it were a full and balanced tree.

\citet{seres1999algebra} describe a breadth-first search 
strategy. We present another implementation. Our implementation is semantically 
equivalent to theirs. But, ours is shorter and performs better in comparison 
with a straightforward translation of their Haskell code.

\NOTE[DPF]{We might find the reference Ocanren in the two Dmitri's paper
and say something here about it.}

\section{conclusion}

We analyze the definitions of fair \disj{} and fair \conj{}, then propose a 
new definition of fair \conj{}. Our definition is orthogonal with completeness.

We devise two new search strategies (i.e. balanced interleaving DFS 
(\DFSbi{}) and fair DFS (\DFSf{})) and devise a new 
implementation of \BFS. These strategies have different features 
in fairness: \DFSbi{} has an almost-fair \disj{} and unfair \conj{}. 
\DFSf{} has fair \disj{} and unfair \conj{}. \BFS{} has both fair
\disj{} and fair \conj{}.

Our quantitative evaluation shows that \DFSbi{} and \DFSf{} are competitive 
alternatives to \DFSi{}, the current search strategy miniKanren
and that \BFS{} is less practical.
% and that \BFSser{} is less practical than other breadth-first strategies.

Our improved \BFS{} is semantically equivalent to the original 
one. But, ours is shorter and performs better in comparison with a 
straightforward translation of their Haskell code.

% We acknowledge that we are making large claims about efficiency given
% that we have just a few benchmarks, but our intuition is based on
% sound principles.

\NOTE[DPF]{Finish this paragraph with a clarification and you may
place this anywhere in the conclusion. This may require some consultation with 
Weixi.}
\NOTE[LKC]{I will do it later.}

\section*{acknowledgments}

\bibliographystyle{ACM-Reference-Format}
\bibliography{citation}

\end{document}

