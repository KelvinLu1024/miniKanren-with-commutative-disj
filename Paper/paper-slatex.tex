\documentclass[format=acmlarge, review=true, authordraft=true]{acmart}

%% scheme-list :
\usepackage{listings}
\usepackage{color}
\usepackage{textcomp}
\usepackage{trackchanges}

%% slatex
\usepackage{slatex}
\setkeyword{defrel conde fresh run}
\setspecialsymbol{==}{$\equiv$}
\setspecialsymbol{conde}{\textbf{cond$^e$}}
\setspecialsymbol{append-inf}{append$^\infty$}
\setspecialsymbol{append-inf/fair}{append$^\infty_f$}
\setspecialsymbol{append-inf/fair^}{append$^\infty_f$\textasciicircum}
\setspecialsymbol{append-map-inf}{append-map$^\infty$}
\setspecialsymbol{append-map-inf/fair}{append-map$^\infty_f$}
\setspecialsymbol{repeato}{repeat$^o$}
\setspecialsymbol{appendo}{append$^o$}
\setspecialsymbol{very-recursiveo}{very-recursive$^o$}
\setspecialsymbol{g1}{$g_1$}
\setspecialsymbol{g2}{$g_2$}
\setspecialsymbol{g3}{$g_3$}
\setspecialsymbol{gs1}{$gs_1$}
\setspecialsymbol{gs2}{$gs_2$}
\setspecialsymbol{ks}{$k_s$}
\setspecialsymbol{kf}{$k_f$}
\setspecialsymbol{s-inf}{s$^\infty$}
\setspecialsymbol{t-inf}{t$^\infty$}
\setspecialsymbol{prod}{$\times$}
\setspecialsymbol{->}{$\rightarrow$}
\setspecialsymbol{#|}{\texttt{\#{}|}}
\setspecialsymbol{|#}{\texttt{|\#{}}}
\def\variablefont#1{{\tt#1\/}} 
\def\datafont#1{{\tt#1\/}} 
\def\constantfont#1{{\tt#1\/}}


%% scheme-list configuration
\lstset{
	language=Scheme,
	basicstyle=\ttfamily,
	morekeywords={run,conde,run*,defrel,==,fresh},
	alsodigit={!\$\%&*+-./:<=>?@^_~},
	morecomment=[l]{;,\#{}lang},
	mathescape=true
}

\addeditor{MVC}
\addeditor{LKC}

% metadata

\title{miniKanren with fair search strategies}
\author{Kuang-Chen Lu}
\affiliation{Indiana University}
\author{Weixi Ma}
\affiliation{Indiana University}
\author{Daniel P. Friedman}
\affiliation{Indiana University}




%%% NOTE %%%
%
%  SUBMISSION DEADLINE: May 15, 2019
%
%%%%%%%%%%%%


\newtheorem{defn}{Definition}[section]

% abbreviations
\newcommand{\dfsi}[0]{DFS$_\textrm{i}$}
\newcommand{\dfsbi}[0]{DFS$_\textrm{bi}$}
\newcommand{\dfsf}[0]{DFS$_\textrm{f}$}

\begin{document}

\begin{abstract}

The syntax of a programming language should reflect its semantics. When writing 
a \scheme|conde| expression in miniKanren, a programmer would expect all clauses 
share the same chance of being explored, as these clauses are written in 
parallel. The existing search strategy, interleaving DFS (DFS$_\textrm{i}$), 
however, prioritize its clauses by the order how they are written down. 
Similarly, when a \scheme|conde| is followed by another goal conjunctively, a 
programmer would expect answers in parallel share the same chance of being 
explored. Again, the answers by DFS$_\textrm{i}$ is different from the 
expectation. We have devised three new search strategies that have different 
level of fairness in \scheme|disj| and \scheme|conj|.

\end{abstract}

\maketitle

\section{introduction}

miniKanren is a family of relational programming languages. miniKanren
programs, especially relational interpreters, have been proven to be
useful in solving many problems by \citet{byrd2017unified}. 

A subtlety in writing miniKanren programs with large \scheme|conde| expressions, 
such as relational interpreters, is that the order of \scheme|conde| clauses 
sometimes affect the speed considerably. This phenomenon also appears when 
running miniKanren programs with the implementation in 
\citet{friedman_reasoned_2018}, one of the most well-understood implementation. 
This is because the search strategy of this implementation, interleaving 
depth-first search (\dfsi), gives left clauses higher ``search priority'' when a 
\scheme|conde| has more than two clauses. The situation is exacerbated as the 
number of clauses increases. This unfair treatment causes two problems when a 
\scheme|conde| expression has many clauses: the right-most clause can hardly 
contribute to query result; and programmers might need to tweak the clause order 
to maximize their programs' efficiency, depending on the distribution of 
queries.

The specification that every clause in the same \scheme|conde| is given equal 
``search priority'' is called fair \scheme|disj|. And search strategies with 
\emph{almost-fair} \scheme|disj| should give every clauss in the same 
\scheme|conde| similar priority. A related concept, fair \scheme|conj| is more 
complicated. We defer it to the next section.

To summarize our contribution, we
\begin{itemize}
    \item analyze an existing concept, fair \scheme|disj| by 
\citet{seres1999algebra}.
	\item propose a new concept, almost-fair \scheme|disj|.
	\item propose a new definition of fair \scheme|conj|.
	\item propose and implement balanced interleaving depth-first search 
	(DFS$_\textrm{bi}$), a new search strategy with almost-fair \scheme|disj|.
	\item propose and implement fair depth-first search (DFS$_\textrm{f}$), a 
	new search strategy with fair \scheme|disj|.
	\item implement in a new way breath-first search (BFS), a search strategy 
	with fair \scheme|disj| and fair \scheme|conj|
	(our code runs faster in all benchmarks and is simpler)
	\item prove our BFS implementation is equivalent with the one by 
	\citet{seres1999algebra}.
\end{itemize}


% A comparison of fairness of search strategies is in Fig.~\ref{fairness}.
 
% \begin{figure}[tbp]
% 	\begin{tabular}{|c|c|c|c|c|}
% 		\hline 
% 		fairness & DFS$_\textrm{i}$ & DFS$_\textrm{bi}$ & DFS$_\textrm{f}$ & BFS \\ 
% 		\hline 
% 		disj & unfair & almost-fair & fair & fair \\ 
% 		\hline 
% 		conj & unfair & unfair & unfair & fair \\ 
% 		\hline 
% 	\end{tabular} 
% 	\caption{fairness of search strategies}
% 	\label{fairness}
% \end{figure}

\section{fairness}

Before going further into fairness, we would like to give a short review about 
state, search space, and goal, because fairness is defined in terms of them. 
Every answer given by miniKanren corresponds to a state. Each state records a 
way how some relations can be satisfied. In our case, the state is just a 
subsitution associating logic variables with terms. In more expressive 
miniKanrens (e.g. miniKanren with with symbolic constraints 
\citep{hemann2017framework}), states can include more information. A search 
space is a collection of states. And a goal is a function from a state to a 
search space. Goals check their input states and outputs possibly extended 
states. A goal might fail for some inputs, in which case the output search 
space would be empty.

Now we elaborate fairness by running queries about \scheme|repeato|, a 
relational definition that relates a term \scheme|x| with a non-empty list whose 
elements are \scheme|x| (Fig.~\ref{repeato}).

% 
% \begin{defn}[fair \scheme|conj|]
% A \scheme|conj| is fair iff it allocates computational resource evenly to 
% search spaces derived from states in the same bag, where bags are finite 
% list of states.
% \end{defn}

\begin{figure}
	\schemeinput{Figures/repeato.rkt}
	\caption{\texttt{repeat$^o$} and an example run}
	\label{repeato}
\end{figure}

\subsection{fair \texttt{disj}}

Given the following program, it is natural to expect lists of each letter to
constitute $1/4$ in the answer. DFS$_\textrm{i}$, the current search
strategy, however, results in many more lists of \scheme|a|s than lists
of other letters. And some letters, e.g. \scheme|c| and \scheme|d|, are
rarely seen. The situation would be exacerbated if \scheme|conde| 
contains more clauses.

\begin{center}
    \begin{schemeregion}
    \schemeinput{Figures/repeato-disj-iDFS.rkt}
    \end{schemeregion}
\end{center}

Under the hood, the \scheme|conde| here is allocating computational effort to 
four trivially different search space. The unfair \scheme|disj| in 
\dfsi{} allocates much more effort to the first search space. On the contrary, 
fair \scheme|disj|s would allocate effort evenly to each search space.

\begin{center}
    \begin{schemeregion}
    \schemeinput{Figures/repeato-disj-DFSf.rkt}
    \end{schemeregion}
\end{center}

\begin{center}
    \begin{schemeregion}
    \schemeinput{Figures/repeato-disj-BFS.rkt}
    \end{schemeregion}
\end{center}

Running the same program again with almost-fair \scheme|disj| 
(e.g. DFS$_\textrm{bi}$) gives the same result. Almost-fair, however, is not 
completely fair, as shown by the following example. 

\begin{center}
    \begin{schemeregion}
    \schemeinput{Figures/repeato-disj-biDFS.rkt}
    \end{schemeregion}
\end{center}

DFS$_\textrm{bi}$ is fair only when the number of goals is a power of 2, 
otherwise, some goals are allocated twice as many resources than the others. In 
the above example, where the \scheme|conde| has five clauses, the clauses of 
\scheme|b|, \scheme|c|, and \scheme|d| are allocated more resources.

We end this subsection with precise definitions of all levels of 
\scheme|disj| fairness.

Our definition of \emph{fair} \scheme|disj| is slightly generalize from the one 
by \citet{seres1999algebra}. Their definition is for binary disjunct. We 
generalize it to multi-arity one.

\begin{defn}[fair \scheme|disj|]
A \scheme|disj| is fair iff it allocates computational resource evenly to 
search spaces produced by goals in the same disjunct (e.g. clauses in the 
same 
\scheme|conde|).
\end{defn}

\begin{defn}[almost-fair \scheme|disj|]
A \scheme|disj| is almost-fair iff it allocates computational resource so 
evenly to search spaces produced by goals in the same disjunct that the maximal 
ratio of resources is bounded by a constant.
\end{defn}

\begin{defn}[unfair \scheme|disj|]
A \scheme|disj| is unfair iff it is not even almost-fair.
\end{defn}


\subsection{fair \texttt{conj}}

In the following program, the three \scheme|conde| clauses differ in a trivial way. So 
we expect lists of each letter constitute $1/4$ of the answer list. Search 
strategies with unfair \scheme|conj| (e.g. DFS$_\textrm{i}$, DFS$_\textrm{f}$), 
however, give us many more lists of \scheme|a|s than lists of other letters. 
And some letters (e.g. lists 
of \scheme|c|) are rarely found. Although DFS$_\textrm{i}$'s \scheme|disj| is unfair in general, 
it is fair when there is no call to relational definition in sub-goals, 
including this case. The situation would be worse if we add more \scheme|conde| 
clauses. The result with DFS$_\textrm{bi}$, whose \scheme|conj| is also unfair, is similar, but 
due to its different \scheme|disj|, the position of \scheme|b| and \scheme|c| are 
swapped. 

\begin{center}
	\begin{schemeregion}
    \schemeinput{Figures/repeato-conj-iDFS.rkt}
	\end{schemeregion}
\end{center}

\begin{center}
	\begin{schemeregion}
    \schemeinput{Figures/repeato-conj-fDFS.rkt}
	\end{schemeregion}
\end{center}

Intuitively, search strategies with fair \scheme|conj| should produce each letter of 
lists equally frequently. Indeed, BFS does so.

\begin{center}
	\begin{schemeregion}
    \schemeinput{Figures/repeato-conj-fair.rkt}
	\end{schemeregion}
\end{center}

A more interesting situation is when the first conjunctive goal produces 
infinite many answers. Consider the following example, a naive specification of 
fair \scheme|conj| might require search strategies to produce all sorts of singleton 
lists, but no longer ones, which makes the strategies \emph{incomplete}. 

\NOTE[MVC]{incomplete w.r.t. what? where's the definition of incomplete?}

\NOTE[LKC]{I am a bit confused. I assume completeness is a well-known concept 
in the context of logic programming. For example, this paper doesn't cite any 
source when it talks about completeness.

Hemann, Jason, et al. "A small embedding of logic programming with a simple 
complete search." ACM SIGPLAN Notices. Vol. 52. No. 2. ACM, 2016.}

\begin{center}
	\begin{schemeregion}
    \schemeinput{Figures/repeato-conj-infinite-naive.rkt}
	\end{schemeregion}
\end{center}

Our solution requires a search strategy with \emph{fair} \scheme|conj| to 
package answers in bags, where each bag contains finite answers, and to allocate 
resources evenly among search spaces derived from answers in the same bag. The 
way to package depends on search strategy. And how to allocate resources among 
search space related to different bags is unspecified. Our definition of fair 
\scheme|conj| is orthogonal with completeness. For example, a naively fair strategy 
is fair but not complete, while BFS is fair and complete. 
\NOTE[MVC]{Also here, complete w.r.t what?}

BFS packages answers by their costs. The \emph{cost} of a answer is its 
depth in the search tree (i.e. the number of calls to relational definitions 
required to find them) \citet{seres1999algebra}. In the following example, 
every answer is a list of list of symbol. The cost of each of them is equal to 
the length of the inner lists plus the length of the outer list. In addition to 
being fair, BFS also produces answers in increasing order of cost.
\NOTE[MVC]{Here inner and outer are very confusing. Can you be more specified?}
\NOTE[LKC]{updated}

\begin{center}
	\begin{schemeregion}
		\schemeinput{Figures/repeato-conj-infinite-sof.rkt}
	\end{schemeregion}
\end{center}

\section{balanced interleaving depth-first search}

\begin{figure}
	\schemeinput{Figures/balanced-disj.rkt}
	\caption{DFS$_\textrm{bi}$ implementation}
	\label{balanced-disj}
\end{figure}

Balanced interleaving DFS (DFS$_\textrm{bi}$) has almost-fair \scheme|disj| and unfair \scheme|conj|. 
The implementation of DFS$_\textrm{bi}$ differs from DFS$_\textrm{i}$ in the \scheme|disj| macro. We list the 
new \scheme|disj| with its helpers in Fig.~\ref{balanced-disj}. The first helper 
function, \scheme{split}, takes a list of goals \scheme{ls} and a procedure 
\scheme{k}, partitions \scheme{ls} into two sub-lists of roughly equal length, 
and returns the application of \scheme{k} to the two sub-lists. \scheme{disj*} 
takes a non-empty list of goals \scheme{gs} and returns a goal. With the help 
of \scheme{split}, it essentially constructs a \emph{balanced} binary tree 
where leaves are elements of \scheme{gs} and nodes are \scheme{disj2}s, hence 
the name of this search strategy. In contrast, the \scheme|disj| in DFS$_\textrm{i}$
constructs the binary tree with the same nodes but in the unbalanced form.

\section{fair depth-first search}

\begin{figure}
	\schemeinput{Figures/fDFS.rkt}
	\caption{DFS$_\textrm{f}$ implementation}
	\label{fDFS}
\end{figure}

Fair DFS (DFS$_\textrm{f}$) has fair \scheme|disj| and unfair \scheme|conj|. The implementation of DFS$_\textrm{f}$ 
differs from DFS$_\textrm{i}$'s in \scheme{disj2} (Fig.~\ref{fDFS}). \scheme{disj2} is 
changed to call a new and fair version of \scheme{append-inf}. 
\scheme{append-inf/fair} immediately calls its helper, 
\scheme{append-inf/fair^}, with the first argument, \scheme{s?}, set to 
\scheme{#t}, which indicates that \scheme{s-inf} and \scheme{t-inf} haven't 
been swapped. The swapping happens at the third \scheme{cond} clause in the 
helper, where \scheme{s?} is updated accordingly. The first two \scheme{cond} 
clauses essentially copy the \scheme{car}s and stop recursion when one of the 
input spaces is obviously finite. The third clause, as we mentioned above, is 
just for swapping. When the fourth and last clause runs, we know that both 
\scheme{s-inf} and \scheme{t-inf} are ended with a thunk. In this case, a new 
thunk is constructed. The new thunk calls the driver recursively. Here changing 
the order of \scheme{t-inf} and \scheme{s-inf} won't hurt the fairness (though 
it will change the order of answers). We swapped them back so that answers are 
produced in a more natural order.


\section{breadth-first search}

BFS is fair in both \scheme|disj| and \scheme|conj|. Our implementation is based on 
DFS$_\textrm{f}$ (not DFS$_\textrm{i}$). All we have to do is apply two trivial changes to 
\scheme{append-map-inf}. First, rename it to \scheme{append-map-inf/fair}. 
Second, replace its use of \scheme{append-inf} to \scheme{append-inf/fair}. 

The implementation can be improved in two ways. First, as mentioned in 
section 2.2, BFS puts answers in bags and answers of the same cost are in the 
same bag. In this implementation, however, it is unclear where this information 
is recorded. Second, 
\scheme{append-inf/fair} is extravagant in memory usage. It makes 
$O(n+m)$ new \scheme{cons} cells every time, where $n$ and $m$ are the 
``length''s of input search spaces. We address these issues in the first 
subsection.

Both our BFS and Seres's BFS \citet{seres1999algebra} produce answers in 
increasing order of cost. So it is interesting to see if they are equivalent. 
We prove so in Coq. The details are in the second subsection.

\subsection{optimized BFS}

\begin{figure}
	\schemeinput{Figures/BFS-opt.rkt}	
	\caption{new and changed functions in optimized BFS that implements pure 
	features}
	\label{BFS-opt}
\end{figure}

\NOTE[MVC]{Though bag is well known, people rarely say ``bagging''. How about putting information in a bag, or something better?}
\NOTE[MVC]{What is the bagging information?}
\NOTE[LKC]{It's just cost... You're right. I should have be more direct.}

As mentioned in section 2.2, BFS puts answers in bags and answers of the 
same cost are in the same bag. The cost
information is recorded subtly -- the \scheme{car}s of a search space have cost 
0 (i.e. they are in the same bag), and the costs of answers in thunk are 
computed recursively then increased by one. It is even more subtle that
\scheme{append-inf/fair} and the \scheme{append-map-inf/fair} respects the cost 
information. We make these facts more obvious by changing the type of search 
space, modifying related function definitions, and introducing a few more 
functions.

The new type is a pair whose \scheme{car} is a list of answers (the bag), and 
whose \scheme{cdr} is either a \scheme{#f} or a thunk returning a search 
space. A falsy \scheme{cdr} means the search space is obviously finite. 

Functions related to the pure subset are listed in Fig.~\ref{BFS-opt} (the 
others in Fig.~\ref{BFS-opt-cont}). They are compared with 
\citeauthor{seres1999algebra}'s implementation later. The first three functions 
in Fig.~\ref{BFS-opt} are search space constructors. \scheme{none} makes an 
empty search space; \scheme{unit} makes a space from one answer; and 
\scheme{step} makes a space from a thunk. The remaining functions do the same 
thing as before. 

Luckily, the change in \scheme{append-inf/fair} also fixes the miserable space 
extravagance -- the use of \scheme{append} helps us to reuse the first bag of 
\scheme{t-inf}.

\citet{kiselyov2005backtracking} has shown that a \emph{MonadPlus} hides in 
implementations of logic programming system. Our BFS implementation is not an 
exception: \scheme{none}, \scheme{unit}, \scheme{append-map-inf}, and 
\scheme{append-inf} correspond to \scheme{mzero}, \scheme{unit}, \scheme{bind}, 
and \scheme{mplus} respectively.

\begin{figure}
	\schemeinput{Figures/BFS-opt-cont.rkt}	
	\caption{new and changed functions in optimized BFS that implements impure 
		features}
	\label{BFS-opt-cont}
\end{figure}

Functions implementing impure features are in Fig.~\ref{BFS-opt-cont}. The 
first function, \scheme{elim}, takes a space \scheme{s-inf} and two 
continuations \scheme{ks} and \scheme{kf}. When \scheme{s-inf} contains some 
answers, \scheme{ks} is called with the first answer and the rest space. 
Otherwise, \scheme{kf} is called with no argument. Here `s' and `f' means 
`succeed' and `fail' respectively. This function is an eliminator of search 
space, hence the name. The remaining functions do the same thing as before.

\subsection{comparison with the BFS of \citet{seres1999algebra}}

In this section, we compare the pure subset of our optimized BFS with the BFS 
found in \citet{seres1999algebra}. We focus on the pure subset because 
Silvija's system is pure. Their system represents search spaces with streams of 
lists of answers, where each list is a bag.

To compare efficiency, we translate her Haskell code into Racket (See 
supplements for the translated code). The translation is direct 
due to the similarity in both logic programming systems and search space 
representations. The translated code is longer and slower. Details about 
difference in efficiency are in section 6.

We prove in Coq that the two BFSs are equivalent, i.e. \scheme{(run n g)} 
produces the same result (See supplements for the formal proof).

\section{quantitative evaluation}

\begin{table}
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline 
		benchmark & size & DFS$_\textrm{i}$ & DFS$_\textrm{bi}$ & DFS$_\textrm{f}$ & optimized BFS & Silvija's BFS  
		\\
		\hline
		very-recursiveo & 100000 &  579 &  793 & 2131 & 1438 & 3617 \\
		& 200000 & 1283 & 1610 & 3602 & 2803 & 4212 \\
		& 300000 & 2160 & 2836 &    - & 6137 &    - \\
		\hline 
		appendo  & 100 &  31 &  41 &  42 &  31 &  68 \\ 
		& 200 & 224 & 222 & 221 & 226 & 218 \\ 
		& 300 & 617 & 634 & 593 & 631 & 622 \\ 
		\hline 
		reverso & 10 &   5 &   3 &   3 &     38 &     85 \\ 
		& 20 & 107 &  98 &  51 &   4862 &   5844 \\
		& 30 & 446 & 442 & 485 & 123288 & 132159 \\ 
		\hline
		quine-1 & 1 &  71 &  44 & 69 & - & - \\ 
		& 2 & 127 & 142 & 95 & - & - \\ 
		& 3 & 114 & 114 & 93 & - & - \\ 
		\hline
		quine-2 & 1 & 147 & 112 &  56 & - & - \\ 
		& 2 & 161 & 123 & 101 & - & - \\ 
		& 3 & 289 & 189 & 104 & - & - \\ 
		\hline 
		'(I love you)-1 &  99 & 56 & 15 & 22 &  74 & 165 \\ 
		& 198 & 53 & 72 & 55 &  47 &  74 \\
		& 297 & 72 & 90 & 44 & 181 & 365 \\ 
		\hline
		'(I love you)-2 &  99 & 242 &  61 & 16 &  66 &  99 \\ 
		& 198 & 445 & 110 & 60 &  42 &  64 \\
		& 297 & 476 & 146 & 49 & 186 & 322 \\ 
		\hline 
	\end{tabular}
	\caption{The results of a quantitative evaluation: running times of 
	benchmarks 
		in milliseconds}
	\label{compare-efficiency}
\end{table}

In this section, we compare the efficiency of search strategies. A concise 
description is in Table~\ref{compare-efficiency}. A hyphen means running out of 
memory. The first two benchmarks are taken from 
\citet{friedman_reasoned_2018}. \scheme{reverso} is from 
\citet{rozplokhas2018improving}. Next two benchmarks 
about quine are modified from a similar test case in \citet{byrd2017unified}. 
The modifications are made 
to circumvent the need for symbolic constraints (e.g. $\neq$, 
\scheme{absento}). Our version generates de 
Bruijnized expressions and prevent closures getting into list. The two 
benchmarks differ in the \scheme|conde| clause order of their relational interpreters. 
The last two 
benchmarks are about synthesizing expressions that evaluate to \scheme{'(I love 
you)}. This benchmark is also inspired by \citet{byrd2017unified}. Again, the 
sibling benchmarks differ in the \scheme|conde| clause order of their relational 
interpreters. The first one 
has elimination rules (i.e. application, \scheme{car}, and \scheme{cdr}) at the 
end, while the other has them at the beginning. We conjecture that DFS$_\textrm{i}$ would 
perform badly in the second case because elimination rules complicate the 
problem when running backward. The evaluation supports our conjecture.

In general, only DFS$_\textrm{i}$ and DFS$_\textrm{bi}$ constantly perform well. DFS$_\textrm{f}$ is just as 
efficient in all benchmarks but \scheme{very-recursiveo}. Both BFS have obvious 
overhead in many cases. Among the three variants of DFS (they all have unfair 
\scheme|conj|), DFS$_\textrm{f}$ is most resistant to clause permutation, followd by DFS$_\textrm{bi}$ then 
DFS$_\textrm{i}$. Among the two implementation of BFS, ours constantly performs as well or 
better. Interestingly, every strategies with fair \scheme|disj| suffers in 
\scheme{very-recursiveo} and DFS$_\textrm{f}$ performs well elsewhere. 
Therefore, this 
benchmark might be a special case. Fair \scheme|conj| imposes overhead constantly 
except in \scheme{appendo}. The reason might be that strategies with fair 
\scheme|conj| tend to keep more intermediate answers in the memory.

\section{related works}

Edward points out a disjunct complex would be `fair' if it is a full and 
balanced tree \citet{yang2010adventures}.

Silvija et al \citet{seres1999algebra} also describe a breadth-first search 
strategy. We proof their BFS is equivalent to ours. But our code looks simpler 
and performs better in comparison with a straightforward translation of their 
Haskell code.

\section{conclusion}

We analysis the definitions of fair \scheme|disj| and fair \scheme|conj|, then propose a 
new definition of fair \scheme|conj|. Our definition is orthogonal with completeness.

We devise three new search strategies: balanced interleaving DFS (DFS$_\textrm{bi}$), fair 
DFS (DFS$_\textrm{f}$), and BFS. DFS$_\textrm{bi}$ has almost-fair \scheme|disj| and unfair \scheme|conj|. DFS$_\textrm{f}$ has 
fair \scheme|disj| and unfair \scheme|conj|. BFS has both fair \scheme|disj| and fair \scheme|conj|.

Our quantitative evaluation shows that DFS$_\textrm{bi}$ and DFS$_\textrm{f}$ are competitive 
alternatives to DFS$_\textrm{i}$, the current search strategy, and that BFS is less 
practical.

We prove our BFS is equivalent to the BFS in \citet{seres1999algebra}. Our code 
is shorter and runs faster than a direct translation of their Haskell code.

\section*{acknowledgments}

\bibliographystyle{ACM-Reference-Format}
\bibliography{citation}

\end{document}

